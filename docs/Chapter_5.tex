\section{Тестирование на полных данных}
\label{sec:Chapter_5} \index{Chapter_5}
\large

\subsection{Постановка задачи}

После реализации всех моделей и сравнения полученных результатов, был выбран алгоритм DDM + LambdaRank для тестирования на полных данных. Ранее, для сравнения моделей строился частичный набор данных, состоящий из правильно подобранных гиперонимов и произвольных 500 слов (отрицательные примеры) для каждого гипонима. Полные данные подразумевают ранжирование всего словаря (более 200 тысяч слов) для каждого отдельно взятого гипонима. Такой подход позволяет в точности оценить качество модели, но требует значительного времени. 

Первая попытка показала низкие результаты:
\begin{itemize}
\item MRR: 0.09649
\item MAP: 0.08239
\item P@1: 0.09343
\item P@3: 0.08119
\item P@5: 0.08166
\item P@15: 0.08305
\end{itemize}

Связано это с тем, что модель LambdaRank обучалась только на явных положительных и отрицательных примерах. Такая модель смогла выучить только тривиальные закономерности, аналогичные тому, сколько раз встретилась пара слов в ProBase. Тем не менее результат в несколько раз превосходит использования шаблонных методов, построенных на том же словаре ProBase. 

Чтобы лучше отделять пограничные примеры (похожие на положительные, но тем не менее являющиеся отрицательными), необходимо при составлении набора данных для алгоритма LambdaRank добавить такие случаи. Проблема состоит в том, как найти такие примеры. Составление ручной разметки требует пересмотра всего большого словаря для каждого слова. Кроме того, необходимо создать критерий, определяющий, является ли слово пограничным. Для каждого алгоритма, каждого его состояния в процессе обучения, такой критерий может быть своим: схожесть слова с правильными гиперонимами зависит от текущих скрытых параметров модели. 

\subsection{Реализация алгоритма подбора отрицательных примеров}

С похожей проблемой сталкивались разработчики компании Яндекс при обучении нейронной сети DSSM, составляющей ранжированный список сайтов по запросу пользователя. Необходимо было правильно составить список "неправильных" сайтов для каждого запроса. После ряда различных экспериментов они предложили алгоритм отбора таких примеров на каждой эпохе обучения. 

Алгоритм основывался на идеи обучать модель на собственных ошибках. На первой эпохе в качестве отрицательных примеров выбирались N случайных сайтов. На таких данных обучалась модель, а затем предсказывала сайты для тех же запросов. Далее выбирались N ошибочных сайтов, которые оказались выше всех в списке. Они и выбирались в качестве отрицательных примеров для следующей эпохи обучения модели. Такой алгоритм склонен к переобучению, поэтому необходимо проверять результаты каждой эпохи на валидационной выборке. 

Эта идея была реализована для задачи подбора отрицательных примеров гиперонимов. Для каждого гипонима на каждой эпохе отбирались 500 слов, схожих с эталонными гиперонимами, но являющихся ошибочными.

\subsection{Результаты}

Алгоритм, описанный выше, позволяет избавиться от ручной разметки, но тем не менее остается необходимость на каждой эпохе для каждого гипонима предсказывать вероятность каждого слова из словаря и переобучать модель. Из-за такого большого количества операций, время обучения одной эпохи не позволяло проводить множество экспериментов. 

Было проведено 7 эпох. Лучший результат показала модель на пятой эпохе:

\begin{itemize}
\item MRR: 0.09649
\item MAP: 0.08239
\item P@1: 0.09343
\item P@3: 0.08119
\item P@5: 0.08166
\item P@15: 0.08305
\end{itemize}

Видно, что результаты значительно улучшились. 

При просмотре гиперонимов, которых извлекала модель, оказалось, что большинство слов и словосочетаний, находящихся в начале списка, действительно являются правильными гиперонимами. Но при сравнении с эталонным списком, многие из них отмечались ошибочными. Связано это с тем, что эталонный список составлялся по текстовому корпусу UMBC. И найденная моделью DDM пара гипоним-гипероним не встречалась в предложениях этого корпуса, как слова, связанные отношением is-a. Например, пара: \textit{tropical storm - natural disturbance} отмечена ошибочной.

